{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XezjYHhmkTi"
      },
      "source": [
        "# Part 1: Webscrapping Benchmarking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPZ0DrZLmEY8"
      },
      "source": [
        "The news website I have chosen for this project contains a number of articles and it will help me calculate the execution times for web scrapping using two different libraries 'BeautifulSoup' and 'Selenium'. First, let's see how we can scrape data using beautifulSoup."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_FoKIOFVDAM"
      },
      "source": [
        "## Webscrapping using beautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YA9voWBhHKNt"
      },
      "outputs": [],
      "source": [
        "import urllib.request,sys,time\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import sys\n",
        "import time\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LpVC17kVJgN",
        "outputId": "1ec151b0-2db3-4952-a894-e37e3d3ddd53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing page: 1\n",
            "https://www.politifact.com/factchecks/list/?page=1\n",
            "Number of articles found on page: 30\n"
          ]
        }
      ],
      "source": [
        "pagesToGet = 1\n",
        "upperframe = []\n",
        "\n",
        "# Start measuring time\n",
        "start_time = time.time()\n",
        "\n",
        "for page in range(1, pagesToGet + 1):\n",
        "    print('Processing page:', page)\n",
        "    url = 'https://www.politifact.com/factchecks/list/?page=' + str(page)\n",
        "    print(url)\n",
        "\n",
        "    try:\n",
        "        page = requests.get(url)  # Request the webpage\n",
        "    except Exception as e:\n",
        "        error_type, error_obj, error_info = sys.exc_info()\n",
        "        print('ERROR FOR LINK:', url)\n",
        "        print(error_type, 'Line:', error_info.tb_lineno)\n",
        "        continue\n",
        "\n",
        "    time.sleep(2)  # Pause to avoid being blocked\n",
        "    soup = BeautifulSoup(page.text, 'html.parser')\n",
        "    frame = []\n",
        "    links = soup.find_all('li', attrs={'class': 'o-listicle__item'})\n",
        "    num_articles = len(links)\n",
        "    print(f'Number of articles found on page: {num_articles}')\n",
        "\n",
        "    filename = \"NEWS_beautifulSoup.csv\"\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        headers = \"Statement,Link,Source\\n\"\n",
        "        f.write(headers)\n",
        "\n",
        "        for j in links:\n",
        "            Statement = j.find(\"div\", attrs={'class': 'm-statement__quote'}).text.strip()\n",
        "            Link = \"https://www.politifact.com\" + j.find(\"div\", attrs={'class': 'm-statement__quote'}).find('a')['href'].strip()\n",
        "            Source = j.find('div', attrs={'class': 'm-statement__meta'}).find('a').text.strip()\n",
        "            \n",
        "            frame.append((Statement, Link, Source))\n",
        "            f.write(Statement.replace(\",\", \"^\") + \",\" + Link + \",\" +  \",\" + Source.replace(\",\", \"^\") + \",\" + \"\\n\")\n",
        "\n",
        "    upperframe.extend(frame)\n",
        "\n",
        "# End measuring time\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLWRIQXOkrHS",
        "outputId": "3c4bdf6e-a5c9-443e-d304-3010a4460946"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total Execution Time: 3.43 seconds\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(f\"\\nTotal Execution Time: {execution_time:.2f} seconds\")\n",
        "\n",
        "# Convert data to a Pandas DataFrame\n",
        "data = pd.DataFrame(upperframe, columns=['Statement', 'Link',  'Source'])\n",
        "data.head()\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "data.to_csv('NEWS_beautifulSoup.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Statement",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Link",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Source",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "06b51846-09d4-4745-a651-69e9ed348e5f",
              "rows": [
                [
                  "0",
                  "“Hillary Clinton was sending classified documents that were stamped TS or TSSCI.”",
                  "https://www.politifact.com/factchecks/2025/mar/28/markwayne-mullin/hillary-clinton-sent-emails-stamped-top-secret-no/",
                  "Markwayne Mullin"
                ],
                [
                  "1",
                  "Image shows a “person dressed up as Pikachu to resist police violence” in Turkey.",
                  "https://www.politifact.com/factchecks/2025/mar/28/social-media/image-of-a-person-dressed-as-pikachu-in-turkey-pro/",
                  "Social Media"
                ],
                [
                  "2",
                  "North Carolina “always had nonpartisan judicial races, and when the Republicans took over several years ago they changed it.”",
                  "https://www.politifact.com/factchecks/2025/mar/28/sydney-batch/democrat-wrongly-says-nc-always-had-nonpartisan-ju/",
                  "Sydney Batch"
                ],
                [
                  "3",
                  "Videos show tornadoes hitting Seattle on March 26 and 27.",
                  "https://www.politifact.com/factchecks/2025/mar/28/tiktok-posts/videos-dont-show-seattle-tornadoes-no-twisters-tou/",
                  "TikTok posts"
                ],
                [
                  "4",
                  "“We have automobile plants being built at levels we've never seen … and they're going up fast.”",
                  "https://www.politifact.com/factchecks/2025/mar/28/donald-trump/fact-checking-donald-trump-on-whether-automobile-p/",
                  "Donald Trump"
                ]
              ],
              "shape": {
                "columns": 3,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Statement</th>\n",
              "      <th>Link</th>\n",
              "      <th>Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“Hillary Clinton was sending classified docume...</td>\n",
              "      <td>https://www.politifact.com/factchecks/2025/mar...</td>\n",
              "      <td>Markwayne Mullin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Image shows a “person dressed up as Pikachu to...</td>\n",
              "      <td>https://www.politifact.com/factchecks/2025/mar...</td>\n",
              "      <td>Social Media</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>North Carolina “always had nonpartisan judicia...</td>\n",
              "      <td>https://www.politifact.com/factchecks/2025/mar...</td>\n",
              "      <td>Sydney Batch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Videos show tornadoes hitting Seattle on March...</td>\n",
              "      <td>https://www.politifact.com/factchecks/2025/mar...</td>\n",
              "      <td>TikTok posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>“We have automobile plants being built at leve...</td>\n",
              "      <td>https://www.politifact.com/factchecks/2025/mar...</td>\n",
              "      <td>Donald Trump</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Statement  \\\n",
              "0  “Hillary Clinton was sending classified docume...   \n",
              "1  Image shows a “person dressed up as Pikachu to...   \n",
              "2  North Carolina “always had nonpartisan judicia...   \n",
              "3  Videos show tornadoes hitting Seattle on March...   \n",
              "4  “We have automobile plants being built at leve...   \n",
              "\n",
              "                                                Link            Source  \n",
              "0  https://www.politifact.com/factchecks/2025/mar...  Markwayne Mullin  \n",
              "1  https://www.politifact.com/factchecks/2025/mar...      Social Media  \n",
              "2  https://www.politifact.com/factchecks/2025/mar...      Sydney Batch  \n",
              "3  https://www.politifact.com/factchecks/2025/mar...      TikTok posts  \n",
              "4  https://www.politifact.com/factchecks/2025/mar...      Donald Trump  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZDROVfAXQBT"
      },
      "source": [
        "## Webscrapping using Selenium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkoeWGHfl75h"
      },
      "source": [
        "let's use the same website to scrape data using library 'Selenium'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in c:\\users\\sanda\\anaconda3\\lib\\site-packages (4.30.0)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: pandas in c:\\users\\sanda\\anaconda3\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: webdriver-manager in c:\\users\\sanda\\anaconda3\\lib\\site-packages (4.0.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.2)\n",
            "Requirement already satisfied: trio~=0.17 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from selenium) (0.29.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from selenium) (2024.8.30)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from selenium) (4.11.0)\n",
            "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: requests in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.32.2)\n",
            "Requirement already satisfied: python-dotenv in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.21.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from webdriver-manager) (23.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
            "Requirement already satisfied: outcome in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.14 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
            "Requirement already satisfied: pycparser in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "pip install selenium pandas webdriver-manager\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEJRVSq6jq-b",
        "outputId": "6cbc6f48-60c3-43fe-c949-7246579751bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Execution Time: 5.457042 seconds\n",
            "Number of articles: 30\n"
          ]
        }
      ],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "\n",
        "# Set up Selenium WebDriver options (headless mode for faster execution)\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")  # Run in the background (no GUI)\n",
        "chrome_options.add_argument(\"--disable-gpu\")\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "\n",
        "# Initialize WebDriver\n",
        "service = Service(ChromeDriverManager().install())\n",
        "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "# Start timing the execution\n",
        "start_time = time.time()\n",
        "\n",
        "# Define the number of pages to scrape\n",
        "pages_to_get = 1  \n",
        "base_url = \"https://www.politifact.com/factchecks/list/?page=\"\n",
        "\n",
        "# Store scraped data\n",
        "scraped_data = []\n",
        "\n",
        "for page in range(1, pages_to_get + 1):\n",
        "    url = base_url + str(page)\n",
        "    driver.get(url)\n",
        "    time.sleep(2)  # Allow time for JavaScript to load\n",
        "\n",
        "    # Locate elements\n",
        "    articles = driver.find_elements(By.CSS_SELECTOR, \"li.o-listicle__item\")\n",
        "\n",
        "    for article in articles:\n",
        "        try:\n",
        "            statement = article.find_element(By.CSS_SELECTOR, \"div.m-statement__quote\").text.strip()\n",
        "        except:\n",
        "            statement = \"No statement found\"\n",
        "        \n",
        "        try:\n",
        "            link = article.find_element(By.CSS_SELECTOR, \"div.m-statement__quote a\").get_attribute(\"href\")\n",
        "        except:\n",
        "            link = \"No link found\"\n",
        "\n",
        "        try:\n",
        "            source = article.find_element(By.CSS_SELECTOR, \"div.m-statement__meta a\").text.strip()\n",
        "        except:\n",
        "            source = \"No source found\"\n",
        "\n",
        "        scraped_data.append((statement, link, source))\n",
        "\n",
        "# Stop timing the execution\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(scraped_data, columns=[\"Statement\", \"URL\", \"Source\"])\n",
        "\n",
        "# Print execution time\n",
        "print(f\"Execution Time: {execution_time:.6f} seconds\")\n",
        "print(f\"Number of articles: {len(articles)}\")\n",
        "\n",
        "# Save results\n",
        "df.to_csv(\"NEWS_Selenium.csv\", index=False)\n",
        "\n",
        "# Close the browser\n",
        "driver.quit()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Statement",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "URL",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Source",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "997d6d56-6994-42df-9d79-2c69c14a2e2f",
              "rows": [
                [
                  "0",
                  "“Hillary Clinton was sending classified documents that were stamped TS or TSSCI.”",
                  "https://www.politifact.com/factchecks/2025/mar/28/markwayne-mullin/hillary-clinton-sent-emails-stamped-top-secret-no/",
                  "Markwayne Mullin"
                ],
                [
                  "1",
                  "Image shows a “person dressed up as Pikachu to resist police violence” in Turkey.",
                  "https://www.politifact.com/factchecks/2025/mar/28/social-media/image-of-a-person-dressed-as-pikachu-in-turkey-pro/",
                  "Social Media"
                ],
                [
                  "2",
                  "North Carolina “always had nonpartisan judicial races, and when the Republicans took over several years ago they changed it.”",
                  "https://www.politifact.com/factchecks/2025/mar/28/sydney-batch/democrat-wrongly-says-nc-always-had-nonpartisan-ju/",
                  "Sydney Batch"
                ],
                [
                  "3",
                  "Videos show tornadoes hitting Seattle on March 26 and 27.",
                  "https://www.politifact.com/factchecks/2025/mar/28/tiktok-posts/videos-dont-show-seattle-tornadoes-no-twisters-tou/",
                  "TikTok posts"
                ],
                [
                  "4",
                  "“We have automobile plants being built at levels we've never seen … and they're going up fast.”",
                  "https://www.politifact.com/factchecks/2025/mar/28/donald-trump/fact-checking-donald-trump-on-whether-automobile-p/",
                  "Donald Trump"
                ]
              ],
              "shape": {
                "columns": 3,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Statement</th>\n",
              "      <th>URL</th>\n",
              "      <th>Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“Hillary Clinton was sending classified docume...</td>\n",
              "      <td>https://www.politifact.com/factchecks/2025/mar...</td>\n",
              "      <td>Markwayne Mullin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Image shows a “person dressed up as Pikachu to...</td>\n",
              "      <td>https://www.politifact.com/factchecks/2025/mar...</td>\n",
              "      <td>Social Media</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>North Carolina “always had nonpartisan judicia...</td>\n",
              "      <td>https://www.politifact.com/factchecks/2025/mar...</td>\n",
              "      <td>Sydney Batch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Videos show tornadoes hitting Seattle on March...</td>\n",
              "      <td>https://www.politifact.com/factchecks/2025/mar...</td>\n",
              "      <td>TikTok posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>“We have automobile plants being built at leve...</td>\n",
              "      <td>https://www.politifact.com/factchecks/2025/mar...</td>\n",
              "      <td>Donald Trump</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Statement  \\\n",
              "0  “Hillary Clinton was sending classified docume...   \n",
              "1  Image shows a “person dressed up as Pikachu to...   \n",
              "2  North Carolina “always had nonpartisan judicia...   \n",
              "3  Videos show tornadoes hitting Seattle on March...   \n",
              "4  “We have automobile plants being built at leve...   \n",
              "\n",
              "                                                 URL            Source  \n",
              "0  https://www.politifact.com/factchecks/2025/mar...  Markwayne Mullin  \n",
              "1  https://www.politifact.com/factchecks/2025/mar...      Social Media  \n",
              "2  https://www.politifact.com/factchecks/2025/mar...      Sydney Batch  \n",
              "3  https://www.politifact.com/factchecks/2025/mar...      TikTok posts  \n",
              "4  https://www.politifact.com/factchecks/2025/mar...      Donald Trump  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCKgYTWOk982"
      },
      "source": [
        "Analysing the total execution time of BeautifulSoup library and Selenium library, it is found that BeautifulSoup execution time is faster than Selenium execution time. Hence we can move forward with BeautifulSoup library to scrape 100 or more articles from the same website we are using. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing page 1...\n",
            "Total articles collected so far: 30\n",
            "Processing page 2...\n",
            "Total articles collected so far: 60\n",
            "Processing page 3...\n",
            "Total articles collected so far: 90\n",
            "Processing page 4...\n",
            "Total articles collected so far: 100\n",
            "\n",
            "Total Articles Scraped: 100\n",
            "Execution Time: 9.28 seconds\n",
            "Shape:  (100, 3)\n",
            "\n",
            "Data saved to NEWS_100_articles.csv\n"
          ]
        }
      ],
      "source": [
        "# Number of articles needed\n",
        "articles_needed = 100\n",
        "collected_articles = 0\n",
        "\n",
        "# Start measuring time\n",
        "start_time = time.time()\n",
        "\n",
        "# Storage for articles\n",
        "article_list = []\n",
        "\n",
        "# Start scraping\n",
        "page = 1\n",
        "\n",
        "while collected_articles < articles_needed:\n",
        "    print(f'Processing page {page}...')\n",
        "    url = f'https://www.politifact.com/factchecks/list/?page={page}'\n",
        "    \n",
        "    try:\n",
        "        page_response = requests.get(url, timeout=10)  # Request with timeout\n",
        "    except Exception as e:\n",
        "        error_type, error_obj, error_info = sys.exc_info()\n",
        "        print(f'ERROR FOR LINK: {url}')\n",
        "        print(error_type, 'Line:', error_info.tb_lineno)\n",
        "        continue\n",
        "\n",
        "    time.sleep(2)  # Pause to avoid being blocked\n",
        "    soup = BeautifulSoup(page_response.text, 'html.parser')\n",
        "    links = soup.find_all('li', attrs={'class': 'o-listicle__item'})\n",
        "\n",
        "    # Extract articles from the page\n",
        "    for j in links:\n",
        "        if collected_articles >= articles_needed:\n",
        "            break  # Stop once we reach 100 articles\n",
        "        \n",
        "        try:\n",
        "            Statement = j.find(\"div\", attrs={'class': 'm-statement__quote'}).text.strip()\n",
        "            Link = \"https://www.politifact.com\" + j.find(\"div\", attrs={'class': 'm-statement__quote'}).find('a')['href'].strip()\n",
        "            Source = j.find('div', attrs={'class': 'm-statement__meta'}).find('a').text.strip()\n",
        "            \n",
        "            article_list.append((Statement, Link, Source))\n",
        "            collected_articles += 1\n",
        "\n",
        "        except AttributeError:\n",
        "            continue  # Skip if any element is missing\n",
        "\n",
        "    print(f\"Total articles collected so far: {collected_articles}\")\n",
        "\n",
        "    page += 1  # Move to the next page\n",
        "\n",
        "# Save to CSV\n",
        "data_100 = pd.DataFrame(article_list, columns=['Statement', 'Link', 'Source'])\n",
        "data_100.to_csv(\"NEWS_100_articles.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "# End measuring time\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "print(f\"\\nTotal Articles Scraped: {len(data_100)}\")\n",
        "print(f\"Execution Time: {execution_time:.2f} seconds\")\n",
        "print(\"Shape: \", data_100.shape)\n",
        "print(\"\\nData saved to NEWS_100_articles.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxtoMmmPnJWz"
      },
      "source": [
        "In the above code, I have scrapped 4 pages to scrape 100 articles using BeautifulSoup. The total execution time for the 100 articles is calculated above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myGfurV2GxLP"
      },
      "source": [
        "# Part 2: Text Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2QN03c8GNAB",
        "outputId": "2f342831-bfaa-483a-897d-487d15a92b27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: vaderSentiment in c:\\users\\sanda\\anaconda3\\lib\\site-packages (3.3.2)\n",
            "Requirement already satisfied: requests in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.32.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sanda\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install vaderSentiment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TolgC2pwKwpg"
      },
      "source": [
        "# TF-IDF and VADER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Statement",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Importance Score",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Direction",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "8e70fd96-8ef8-41d6-9135-4b70b0aa435e",
              "rows": [
                [
                  "0",
                  "“Hillary Clinton was sending classified documents that were stamped TS or TSSCI.”",
                  "0.0",
                  "Negative"
                ],
                [
                  "1",
                  "Image shows a “person dressed up as Pikachu to resist police violence” in Turkey.",
                  "0.045012224595792204",
                  "Negative"
                ],
                [
                  "2",
                  "North Carolina “always had nonpartisan judicial races, and when the Republicans took over several years ago they changed it.”",
                  "0.03177394152222585",
                  "Negative"
                ],
                [
                  "3",
                  "Videos show tornadoes hitting Seattle on March 26 and 27.",
                  "0.0",
                  "Negative"
                ],
                [
                  "4",
                  "“We have automobile plants being built at levels we've never seen … and they're going up fast.”",
                  "0.011346377779128449",
                  "Negative"
                ],
                [
                  "5",
                  "Phoenix’s increased wildfire risk is linked to Bill Gates’ “smart city” plans.",
                  "0.0",
                  "Negative"
                ],
                [
                  "6",
                  "“Canada makes bold decision to shut down Tesla and the US auto industry.”",
                  "0.0",
                  "Positive"
                ],
                [
                  "7",
                  "“Elon Musk exposes hidden $20K roof grant. Congress approved it.\"",
                  "0.0",
                  "Positive"
                ],
                [
                  "8",
                  "\"Brad Schimel said that he wanted to be part of Donald Trump's support network.\"",
                  "0.016784949864136346",
                  "Positive"
                ],
                [
                  "9",
                  "Video shows the Bitcoin whitepaper “was spotted at the White House.”",
                  "0.045012224595792204",
                  "Negative"
                ]
              ],
              "shape": {
                "columns": 3,
                "rows": 10
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Statement</th>\n",
              "      <th>Importance Score</th>\n",
              "      <th>Direction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“Hillary Clinton was sending classified docume...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Image shows a “person dressed up as Pikachu to...</td>\n",
              "      <td>0.045012</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>North Carolina “always had nonpartisan judicia...</td>\n",
              "      <td>0.031774</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Videos show tornadoes hitting Seattle on March...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>“We have automobile plants being built at leve...</td>\n",
              "      <td>0.011346</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Phoenix’s increased wildfire risk is linked to...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>“Canada makes bold decision to shut down Tesla...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>“Elon Musk exposes hidden $20K roof grant. Con...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>\"Brad Schimel said that he wanted to be part o...</td>\n",
              "      <td>0.016785</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Video shows the Bitcoin whitepaper “was spotte...</td>\n",
              "      <td>0.045012</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Statement  Importance Score  \\\n",
              "0  “Hillary Clinton was sending classified docume...          0.000000   \n",
              "1  Image shows a “person dressed up as Pikachu to...          0.045012   \n",
              "2  North Carolina “always had nonpartisan judicia...          0.031774   \n",
              "3  Videos show tornadoes hitting Seattle on March...          0.000000   \n",
              "4  “We have automobile plants being built at leve...          0.011346   \n",
              "5  Phoenix’s increased wildfire risk is linked to...          0.000000   \n",
              "6  “Canada makes bold decision to shut down Tesla...          0.000000   \n",
              "7  “Elon Musk exposes hidden $20K roof grant. Con...          0.000000   \n",
              "8  \"Brad Schimel said that he wanted to be part o...          0.016785   \n",
              "9  Video shows the Bitcoin whitepaper “was spotte...          0.045012   \n",
              "\n",
              "  Direction  \n",
              "0  Negative  \n",
              "1  Negative  \n",
              "2  Negative  \n",
              "3  Negative  \n",
              "4  Negative  \n",
              "5  Negative  \n",
              "6  Positive  \n",
              "7  Positive  \n",
              "8  Positive  \n",
              "9  Negative  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=100)\n",
        "X = vectorizer.fit_transform(data_100['Statement'])\n",
        "\n",
        "# Get top words contributing to importance\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "tfidf_scores = np.mean(X.toarray(), axis=0)\n",
        "important_words = dict(zip(feature_names, tfidf_scores))\n",
        "\n",
        "# Initialize Sentiment Analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "def analyze_text(text):\n",
        "    sentiment = analyzer.polarity_scores(text)\n",
        "    importance_score = sum([important_words.get(word, 0) for word in text.split()])  # Sum TF-IDF scores\n",
        "    direction = \"Positive\" if sentiment['compound'] > 0 else \"Negative\"\n",
        "    return importance_score, direction\n",
        "\n",
        "# Apply analysis to each article\n",
        "data_100[['Importance Score', 'Direction']] = data_100['Statement'].apply(lambda x: pd.Series(analyze_text(x)))\n",
        "\n",
        "# Display results\n",
        "data_100[['Statement', 'Importance Score', 'Direction']].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Analysis completed. Data saved to NEWS_text_analysis_results.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\sanda\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Ensure NLTK sentence tokenizer is downloaded\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "# Initialize TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=100)\n",
        "X = vectorizer.fit_transform(df['Statement'])\n",
        "\n",
        "# Get top words contributing to importance\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "tfidf_scores = np.mean(X.toarray(), axis=0)\n",
        "important_words = dict(zip(feature_names, tfidf_scores))\n",
        "\n",
        "# Initialize Sentiment Analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "def analyze_text(text):\n",
        "    # Compute sentiment scores\n",
        "    sentiment = analyzer.polarity_scores(text)\n",
        "    \n",
        "    # Compute importance score based on TF-IDF word weights\n",
        "    importance_score = sum([important_words.get(word, 0) for word in text.split()])\n",
        "    \n",
        "    # Determine direction\n",
        "    direction = \"Positive\" if sentiment['compound'] > 0 else \"Negative\"\n",
        "\n",
        "    # Extract top 2 sentences with the highest sentiment polarity\n",
        "    sentences = sent_tokenize(text)\n",
        "    sentences_scored = [(sent, analyzer.polarity_scores(sent)['compound']) for sent in sentences]\n",
        "    \n",
        "    # Sort sentences by absolute polarity score and pick top 2\n",
        "    top_sentences = sorted(sentences_scored, key=lambda x: abs(x[1]), reverse=True)[:2]\n",
        "    summary = \" \".join([s[0] for s in top_sentences])\n",
        "\n",
        "    return summary, importance_score, direction\n",
        "\n",
        "# Apply analysis to each article\n",
        "data_100[['Summary', 'Importance Score', 'Direction']] = data_100['Statement'].apply(lambda x: pd.Series(analyze_text(x)))\n",
        "\n",
        "# Reorder columns\n",
        "data_100 = data_100[['Statement', 'Summary', 'Importance Score', 'Direction', 'Link', 'Source']]\n",
        "\n",
        "# Display first few results\n",
        "data_100.head()\n",
        "\n",
        "# Save results to CSV\n",
        "data_100.to_csv(\"NEWS_text_analysis_results.csv\", index=False)\n",
        "print(\"\\nAnalysis completed. Data saved to NEWS_text_analysis_results.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
